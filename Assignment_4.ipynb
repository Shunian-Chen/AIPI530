{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Assignment 4",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shunian-Chen/AIPI530/blob/Assignment4/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBetdmEx_45B"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwFGLT2HYYjp",
        "outputId": "0b190118-ad61-4efc-b4ee-93e42b298f4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL0IZKcr_45C"
      },
      "source": [
        "\n",
        "# Assignment 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh9l-PHjOwjG"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiWW_44T_45F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dfce99f-68e2-4c2d-be65-a9a6ee6ad5e0"
      },
      "source": [
        "!pip install gym-super-mario-bros==7.3.0\n",
        "!pip install git+https://github.com/Shunian-Chen/AIPI530.git@Assignment4\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import deque\n",
        "import random, datetime, os, copy\n",
        "\n",
        "# Gym is an OpenAI toolkit for RL\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "from gym.wrappers import FrameStack\n",
        "\n",
        "# NES Emulator for OpenAI Gym\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "\n",
        "# Super Mario environment for OpenAI Gym\n",
        "import gym_super_mario_bros\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Import DQN and evaluation helper\n",
        "from stable_baselines3 import DQN \n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym-super-mario-bros==7.3.0\n",
            "  Downloading gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 30 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 51 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 198 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting nes-py>=8.0.0\n",
            "  Downloading nes_py-8.1.8.tar.gz (76 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 50.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 55.9 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 30 kB 64.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 68.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 51 kB 62.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 61 kB 65.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71 kB 65.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 76 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.11,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.5.0)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.11,>=1.4.0->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.16.0)\n",
            "Building wheels for collected packages: nes-py\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.1.8-cp37-cp37m-linux_x86_64.whl size=437292 sha256=6d81866fc82e588ef4c8ebf66c1851978f7779a39abf1b55bbe30acb745d5752\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/05/1f/608f15ab43187096eb5f3087506419c2d9772e97000f3ba025\n",
            "Successfully built nes-py\n",
            "Installing collected packages: nes-py, gym-super-mario-bros\n",
            "Successfully installed gym-super-mario-bros-7.3.0 nes-py-8.1.8\n",
            "Collecting git+https://github.com/Shunian-Chen/AIPI530.git@Assignment4\n",
            "  Cloning https://github.com/Shunian-Chen/AIPI530.git (to revision Assignment4) to /tmp/pip-req-build-n52htl93\n",
            "  Running command git clone -q https://github.com/Shunian-Chen/AIPI530.git /tmp/pip-req-build-n52htl93\n",
            "  Running command git checkout -b Assignment4 --track origin/Assignment4\n",
            "  Switched to a new branch 'Assignment4'\n",
            "  Branch 'Assignment4' set up to track remote branch 'Assignment4' from 'origin'.\n",
            "Requirement already satisfied: gym<0.20,>=0.17 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (1.10.0+cu111)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3==1.3.1a1) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3==1.3.1a1) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.20,>=0.17->stable-baselines3==1.3.1a1) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->stable-baselines3==1.3.1a1) (3.10.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a1) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a1) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a1) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3==1.3.1a1) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3==1.3.1a1) (2018.9)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 784 kB in 1s (1,050 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAbRApgm_45G"
      },
      "source": [
        "## Initialize Environment\n",
        "------------------------\n",
        "\n",
        "In Mario, the environment consists of tubes, mushrooms and other\n",
        "components.\n",
        "\n",
        "When Mario makes an action, the environment responds with the changed\n",
        "(next) state, reward and other info.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErPHzOsfY7mo",
        "outputId": "483c8fb5-c801-4ee7-9cfc-b93c997aee31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "PATH = \"/content/drive/Othercomputers/我的笔记本电脑/Google Drive/A4/Mario\"\n",
        "os.chdir(PATH)\n",
        "os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b4949d0bc4f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/Othercomputers/我的笔记本电脑/Google Drive/A4/Mario\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Othercomputers/我的笔记本电脑/Google Drive/A4/Mario'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBWdXUpL_45H"
      },
      "source": [
        "# Initialize Super Mario environment\n",
        "env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\")\n",
        "\n",
        "# Limit the action-space to\n",
        "#   0. walk right\n",
        "#   1. jump right\n",
        "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
        "\n",
        "env.reset()\n",
        "next_state, reward, done, info = env.step(action=0)\n",
        "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drCYGkOG_45H"
      },
      "source": [
        "Preprocess Environment\n",
        "------------------------\n",
        "\n",
        "Environment data is returned to the agent in ``next_state``. As you saw\n",
        "above, each state is represented by a ``[3, 240, 256]`` size array.\n",
        "Often that is more information than our agent needs; for instance,\n",
        "Mario’s actions do not depend on the color of the pipes or the sky!\n",
        "\n",
        "We use **Wrappers** to preprocess environment data before sending it to\n",
        "the agent.\n",
        "\n",
        "``GrayScaleObservation`` is a common wrapper to transform an RGB image\n",
        "to grayscale; doing so reduces the size of the state representation\n",
        "without losing useful information. Now the size of each state:\n",
        "``[1, 240, 256]``\n",
        "\n",
        "``ResizeObservation`` downsamples each observation into a square image.\n",
        "New size: ``[1, 84, 84]``\n",
        "\n",
        "``SkipFrame`` is a custom wrapper that inherits from ``gym.Wrapper`` and\n",
        "implements the ``step()`` function. Because consecutive frames don’t\n",
        "vary much, we can skip n-intermediate frames without losing much\n",
        "information. The n-th frame aggregates rewards accumulated over each\n",
        "skipped frame.\n",
        "\n",
        "``FrameStack`` is a wrapper that allows us to squash consecutive frames\n",
        "of the environment into a single observation point to feed to our\n",
        "learning model. This way, we can identify if Mario was landing or\n",
        "jumping based on the direction of his movement in the previous several\n",
        "frames.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2enViab_45J"
      },
      "source": [
        "class SkipFrame(gym.Wrapper):\n",
        "    def __init__(self, env, skip):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, and sum reward\"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = False\n",
        "        for i in range(self._skip):\n",
        "            # Accumulate reward and repeat the same action\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "\n",
        "class GrayScaleObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs_shape = self.observation_space.shape[:2]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def permute_orientation(self, observation):\n",
        "        # permute [H, W, C] array to [C, H, W] tensor\n",
        "        observation = np.transpose(observation, (2, 0, 1))\n",
        "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
        "        return observation\n",
        "\n",
        "    def observation(self, observation):\n",
        "        observation = self.permute_orientation(observation)\n",
        "        transform = T.Grayscale()\n",
        "        observation = transform(observation)\n",
        "        return observation\n",
        "\n",
        "\n",
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        super().__init__(env)\n",
        "        if isinstance(shape, int):\n",
        "            self.shape = (shape, shape)\n",
        "        else:\n",
        "            self.shape = tuple(shape)\n",
        "\n",
        "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        transforms = T.Compose(\n",
        "            [T.Resize(self.shape), T.Normalize(0, 255)]\n",
        "        )\n",
        "        observation = transforms(observation).squeeze(0)\n",
        "        return observation\n",
        "\n",
        "\n",
        "# Apply Wrappers to environment\n",
        "env = SkipFrame(env, skip=4)\n",
        "env = GrayScaleObservation(env)\n",
        "env = ResizeObservation(env, shape=84)\n",
        "env = FrameStack(env, num_stack=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLaHEi-SwtwX"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-1scts3Y1c7"
      },
      "source": [
        "tensorboard_log = \"data/tb/\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dqn_model = DQN(\"CnnPolicy\",\n",
        "            env,\n",
        "            verbose=1,\n",
        "            train_freq=16,\n",
        "            gradient_steps=8,\n",
        "            gamma=0.99,\n",
        "            exploration_fraction=0.2,\n",
        "            exploration_final_eps=0.07,\n",
        "            target_update_interval=600,\n",
        "            learning_starts=1000,\n",
        "            buffer_size=100000,\n",
        "            batch_size=128,\n",
        "            learning_rate=4e-3,\n",
        "            policy_kwargs=dict(net_arch=[256, 256]),\n",
        "            tensorboard_log=tensorboard_log,\n",
        "            seed=2,\n",
        "            device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn0C7RHyZTHA"
      },
      "source": [
        "mean_reward, std_reward = evaluate_policy(dqn_model, dqn_model.get_env(), deterministic=True, n_eval_episodes=20)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wKP0gKjZgWZ"
      },
      "source": [
        "epoach = int(1e0)\n",
        "save_period = int(1e3)\n",
        "for i in range(epoach):\n",
        "  dqn_model.learn(save_period, log_interval=100)\n",
        "  dqn_model.save(\"dqn_mario\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNjMB14VvkN5"
      },
      "source": [
        "mean_reward, std_reward = evaluate_policy(dqn_model, dqn_model.get_env(), deterministic=True, n_eval_episodes=20)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM0m1NyAgVhR"
      },
      "source": [
        "# Optional: Monitor training in tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $tensorboard_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "## Prepare video recording"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trag9dQpOIhx"
      },
      "source": [
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(env_id, model, video_length=5000, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param env_id: (str)\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = env_id\n",
        "  # Start the video at step=0 and record 500 steps\n",
        "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs, deterministic=False)\n",
        "    obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFiOqKE3aDzI"
      },
      "source": [
        "## Visualize trained agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvVGX13xaGbf"
      },
      "source": [
        "record_video(dqn_model.get_env(), dqn_model, video_length=5000, prefix='dqn-mountaincar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHaYvk8uaK70"
      },
      "source": [
        "show_videos('videos', prefix='dqn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N23kmMzGg_BN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}