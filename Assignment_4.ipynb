{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Assignment 4",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shunian-Chen/AIPI530/blob/Assignment4/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBetdmEx_45B"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL0IZKcr_45C"
      },
      "source": [
        "\n",
        "# Assignment 4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdc88m2SJlI3",
        "outputId": "6f3d1759-6d1a-418b-a188-c909154b099c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 15 20:41:26 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pz5UjDDYuIB",
        "outputId": "adc3e12c-0185-41ef-8d98-b73207bd5c75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MtOaj7sSY1O9",
        "outputId": "2fb33c6c-5ad1-40dc-a237-5a3b31f517a8"
      },
      "source": [
        "import os\n",
        "PATH = \"/content/drive/Othercomputers/我的笔记本电脑/Google Drive/A4\"\n",
        "os.chdir(PATH)\n",
        "os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/Othercomputers/我的笔记本电脑/Google Drive/A4'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh9l-PHjOwjG"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiWW_44T_45F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310897e7-5eb9-4997-df25-2fa108672db4"
      },
      "source": [
        "!pip install gym-super-mario-bros==7.3.0\n",
        "!pip install git+https://github.com/Shunian-Chen/AIPI530.git@Assignment4\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import deque\n",
        "import random, datetime, os, copy\n",
        "\n",
        "# Gym is an OpenAI toolkit for RL\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "from gym.wrappers import FrameStack\n",
        "\n",
        "# NES Emulator for OpenAI Gym\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "\n",
        "# Super Mario environment for OpenAI Gym\n",
        "import gym_super_mario_bros\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Import DQN and evaluation helper\n",
        "from stable_baselines3 import DQN \n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym-super-mario-bros==7.3.0\n",
            "  Downloading gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting nes-py>=8.0.0\n",
            "  Downloading nes_py-8.1.8.tar.gz (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.11,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.5.0)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (4.62.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.11,>=1.4.0->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.16.0)\n",
            "Building wheels for collected packages: nes-py\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.1.8-cp37-cp37m-linux_x86_64.whl size=437385 sha256=4f1c3f23ae61dcaa30febf61a708b1cbad4259acb5edd94a60110581ee6ae459\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/05/1f/608f15ab43187096eb5f3087506419c2d9772e97000f3ba025\n",
            "Successfully built nes-py\n",
            "Installing collected packages: nes-py, gym-super-mario-bros\n",
            "Successfully installed gym-super-mario-bros-7.3.0 nes-py-8.1.8\n",
            "Collecting git+https://github.com/Shunian-Chen/AIPI530.git@Assignment4\n",
            "  Cloning https://github.com/Shunian-Chen/AIPI530.git (to revision Assignment4) to /tmp/pip-req-build-6ymyrcb5\n",
            "  Running command git clone -q https://github.com/Shunian-Chen/AIPI530.git /tmp/pip-req-build-6ymyrcb5\n",
            "  Running command git checkout -b Assignment4 --track origin/Assignment4\n",
            "  Switched to a new branch 'Assignment4'\n",
            "  Branch 'Assignment4' set up to track remote branch 'Assignment4' from 'origin'.\n",
            "Requirement already satisfied: gym<0.20,>=0.17 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (1.10.0+cu111)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.3.1a1) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3==1.3.1a1) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3==1.3.1a1) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.20,>=0.17->stable-baselines3==1.3.1a1) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->stable-baselines3==1.3.1a1) (3.10.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a1) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a1) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.3.1a1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3==1.3.1a1) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3==1.3.1a1) (2018.9)\n",
            "Building wheels for collected packages: stable-baselines3\n",
            "  Building wheel for stable-baselines3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable-baselines3: filename=stable_baselines3-1.3.1a1-py3-none-any.whl size=163781 sha256=951c6e12907d318339293df962980c5d4dd6d8afb3bf1d1adbc4558fc57e3c75\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4gek470c/wheels/5b/6e/14/652c99c5dd22362295f6d97b25c311bc15d2d71b715b451667\n",
            "Successfully built stable-baselines3\n",
            "Installing collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-1.3.1a1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 784 kB in 2s (370 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drCYGkOG_45H"
      },
      "source": [
        "## Preprocess Environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2enViab_45J"
      },
      "source": [
        "class SkipFrame(gym.Wrapper):\n",
        "    def __init__(self, env, skip):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, and sum reward\"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = False\n",
        "        for i in range(self._skip):\n",
        "            # Accumulate reward and repeat the same action\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "\n",
        "class GrayScaleObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs_shape = self.observation_space.shape[:2]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def permute_orientation(self, observation):\n",
        "        # permute [H, W, C] array to [C, H, W] tensor\n",
        "        observation = np.transpose(observation, (2, 0, 1))\n",
        "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
        "        return observation\n",
        "\n",
        "    def observation(self, observation):\n",
        "        observation = self.permute_orientation(observation)\n",
        "        transform = T.Grayscale()\n",
        "        observation = transform(observation)\n",
        "        return observation\n",
        "\n",
        "\n",
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        super().__init__(env)\n",
        "        if isinstance(shape, int):\n",
        "            self.shape = (shape, shape)\n",
        "        else:\n",
        "            self.shape = tuple(shape)\n",
        "\n",
        "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        transforms = T.Compose(\n",
        "            [T.Resize(self.shape), T.Normalize(0, 255)]\n",
        "        )\n",
        "        observation = transforms(observation).squeeze(0)\n",
        "        return observation\n",
        "\n",
        "def prepare_env():\n",
        "  # Initialize Super Mario environment\n",
        "  env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\")\n",
        "\n",
        "  # Limit the action-space to\n",
        "  #   0. walk right\n",
        "  #   1. jump right\n",
        "  env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
        "\n",
        "  env.reset()\n",
        "\n",
        "  next_state, reward, done, info = env.step(action=0)\n",
        "  print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")\n",
        "\n",
        "  # Apply Wrappers to environment\n",
        "  env = SkipFrame(env, skip=4)\n",
        "  env = GrayScaleObservation(env)\n",
        "  env = ResizeObservation(env, shape=84)\n",
        "  env = FrameStack(env, num_stack=4)\n",
        "\n",
        "  return env\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xryKC8eTXBVD",
        "outputId": "4135f6f5-57e4-4e2e-f337-79af012dc3dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "env = prepare_env()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 256, 3),\n",
            " 0,\n",
            " False,\n",
            " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'x_pos_screen': 40, 'y_pos': 79}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLaHEi-SwtwX"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-1scts3Y1c7",
        "outputId": "a683f123-4c55-42ab-e2bd-ddef21f596fb"
      },
      "source": [
        "tensorboard_log = \"data/tb/\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_freq=16\n",
        "epoch = int(5e4) * train_freq\n",
        "save_period = int(1e3) * train_freq\n",
        "save_path = \"dqn_model\"\n",
        "\n",
        "try:\n",
        "  env = prepare_env()\n",
        "  dqn_model = DQN.load(save_path + \"_model\", env = env)\n",
        "  dqn_model.load_replay_buffer(save_path + \"_replay_buffer.pkl\")\n",
        "except:\n",
        "  dqn_model = DQN(\"CnnPolicy\",\n",
        "              env,\n",
        "              verbose=1,\n",
        "              train_freq=16,\n",
        "              gradient_steps=8,\n",
        "              gamma=0.99,\n",
        "              exploration_fraction=0.4,\n",
        "              exploration_final_eps=0.1,\n",
        "              target_update_interval=600,\n",
        "              learning_starts=1000,\n",
        "              buffer_size=10000,\n",
        "              batch_size=256,\n",
        "              learning_rate=4e-3,\n",
        "              policy_kwargs=dict(net_arch=[256, 256]),\n",
        "              tensorboard_log=tensorboard_log,\n",
        "              seed=2,\n",
        "              device = device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 256, 3),\n",
            " 0,\n",
            " False,\n",
            " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'x_pos_screen': 40, 'y_pos': 79}\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn0C7RHyZTHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed68ffb-e88b-4a0f-a630-ac2854426dbd"
      },
      "source": [
        "mean_reward, std_reward = evaluate_policy(dqn_model, dqn_model.get_env(), deterministic=True, n_eval_episodes=20)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:231.00 +/- 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRt_PBmoPe2A"
      },
      "source": [
        "I embeded the saving process inside the .learn() mothod, so that it will automatically save the model at \"save_path\" every \"save_period\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wKP0gKjZgWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed2f3d3-55cc-4001-cb71-8f1e4b214ed7"
      },
      "source": [
        "dqn_model.learn(total_timesteps=epoch, log_interval=20, save_period = save_period, save_path = save_path, reset_num_timesteps = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to data/tb/DQN_31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91       |\n",
            "|    ep_rew_mean      | 415      |\n",
            "|    exploration_rate | 0.105    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4300     |\n",
            "|    fps              | 17       |\n",
            "|    time_elapsed     | 84       |\n",
            "|    total_timesteps  | 527868   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 2.73e+11 |\n",
            "|    n_updates        | 263432   |\n",
            "----------------------------------\n",
            "Steps: 528000, use time: 89.29711961746216, average reward: 403.25!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84       |\n",
            "|    ep_rew_mean      | 386      |\n",
            "|    exploration_rate | 0.102    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4320     |\n",
            "|    fps              | 23       |\n",
            "|    time_elapsed     | 130      |\n",
            "|    total_timesteps  | 529416   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 2.85e+11 |\n",
            "|    n_updates        | 264208   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.2     |\n",
            "|    ep_rew_mean      | 401      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4340     |\n",
            "|    fps              | 26       |\n",
            "|    time_elapsed     | 190      |\n",
            "|    total_timesteps  | 531470   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 2.32e+11 |\n",
            "|    n_updates        | 265232   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.9     |\n",
            "|    ep_rew_mean      | 426      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4360     |\n",
            "|    fps              | 28       |\n",
            "|    time_elapsed     | 247      |\n",
            "|    total_timesteps  | 533417   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 2.66e+11 |\n",
            "|    n_updates        | 266208   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.2     |\n",
            "|    ep_rew_mean      | 419      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4380     |\n",
            "|    fps              | 29       |\n",
            "|    time_elapsed     | 295      |\n",
            "|    total_timesteps  | 535083   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 3.01e+11 |\n",
            "|    n_updates        | 267040   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.5     |\n",
            "|    ep_rew_mean      | 427      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4400     |\n",
            "|    fps              | 30       |\n",
            "|    time_elapsed     | 348      |\n",
            "|    total_timesteps  | 536919   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 2.39e+11 |\n",
            "|    n_updates        | 267960   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.5     |\n",
            "|    ep_rew_mean      | 416      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4420     |\n",
            "|    fps              | 30       |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 538261   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 3.54e+11 |\n",
            "|    n_updates        | 268632   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89       |\n",
            "|    ep_rew_mean      | 412      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4440     |\n",
            "|    fps              | 31       |\n",
            "|    time_elapsed     | 440      |\n",
            "|    total_timesteps  | 540365   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 3.89e+11 |\n",
            "|    n_updates        | 269680   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.8     |\n",
            "|    ep_rew_mean      | 400      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4460     |\n",
            "|    fps              | 32       |\n",
            "|    time_elapsed     | 481      |\n",
            "|    total_timesteps  | 541992   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 3.67e+11 |\n",
            "|    n_updates        | 270496   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.1     |\n",
            "|    ep_rew_mean      | 390      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4480     |\n",
            "|    fps              | 33       |\n",
            "|    time_elapsed     | 526      |\n",
            "|    total_timesteps  | 543789   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 1.65e+11 |\n",
            "|    n_updates        | 271392   |\n",
            "----------------------------------\n",
            "Steps: 544000, use time: 531.8525660037994, average reward: 389.42!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.9     |\n",
            "|    ep_rew_mean      | 380      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4500     |\n",
            "|    fps              | 33       |\n",
            "|    time_elapsed     | 564      |\n",
            "|    total_timesteps  | 545308   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 3.01e+11 |\n",
            "|    n_updates        | 272152   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.2     |\n",
            "|    ep_rew_mean      | 412      |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4520     |\n",
            "|    fps              | 34       |\n",
            "|    time_elapsed     | 616      |\n",
            "|    total_timesteps  | 547378   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.004    |\n",
            "|    loss             | 3.37e+11 |\n",
            "|    n_updates        | 273192   |\n",
            "----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQcJk2gTjklx"
      },
      "source": [
        "mean_reward, std_reward = evaluate_policy(dqn_model, dqn_model.get_env(), deterministic=True, n_eval_episodes=20)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM0m1NyAgVhR"
      },
      "source": [
        "#Monitor training in tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $tensorboard_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "## Prepare video recording"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trag9dQpOIhx"
      },
      "source": [
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(env_id, model, video_length=5000, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param env_id: (str)\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = env_id\n",
        "  # Start the video at step=0 and record 500 steps\n",
        "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs, deterministic=False)\n",
        "    obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFiOqKE3aDzI"
      },
      "source": [
        "## Visualize trained agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvVGX13xaGbf"
      },
      "source": [
        "record_video(dqn_model.get_env(), dqn_model, video_length=1000, prefix='dqn-mario-save')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHaYvk8uaK70"
      },
      "source": [
        "show_videos('videos', prefix='dqn-mario-save')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0GMFvyNbjdY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}